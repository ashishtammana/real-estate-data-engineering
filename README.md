# ğŸ¡ Real Estate Data Engineering Pipeline

This project is an end-to-end **real estate data pipeline** built with **Dagster**, featuring:

âœ… Web-scraping/CSV ingestion  
âœ… Change Data Capture (CDC) logic  
âœ… Uploading to **MinIO** (S3 compatible)  
âœ… Daily scheduled runs with **Dagster**  
âœ… Future-proof for machine learning, Superset dashboards, and more!

---

## ğŸš€ Tech Stack
- ğŸ—ï¸ **Dagster** â€“ Orchestration & scheduling
- ğŸ§º **MinIO** â€“ Object storage (S3 compatible)
- ğŸ“Š **Pandas** â€“ Data processing
- â˜ï¸ **Boto3** â€“ Upload to MinIO
- ğŸ³ **Docker** â€“ For MinIO local setup (optional)
- ğŸ”„ **CDC** â€“ Detect changes and update data

---

## ğŸ”§ How to Run

### 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/ashishtammana/real-estate-data-engineering.git
cd real-estate-data-engineering

### 2ï¸âƒ£ Create and activate a virtual environment
```bash
python3 -m venv venv
source venv/bin/activate

### 3ï¸âƒ£ Install the requirements
```bash
pip install -r requirements.txt

### 4ï¸âƒ£ Set up Dagster environment
export DAGSTER_HOME=~/dagster_home
mkdir -p $DAGSTER_HOME

### 5ï¸âƒ£ Start MinIO (optional if not already running)
```bash
docker-compose up -d

###6ï¸âƒ£ Export Dagster home directory
```bash
export DAGSTER_HOME=~/dagster_home

###7ï¸âƒ£ Start Dagster services
Open two terminals:
Terminal1:
```bash
dagster-daemon run
Terminal2:
```bash
dagster-webserver -w workspace.yaml

###8ï¸âƒ£ Open Dagster UI
Go to http://localhost:3000

###9ï¸âƒ£ Trigger the pipeline
Run real_estate_pipeline manually or wait for the daily schedule.

###âœ… Output
Cleaned data with CDC applied.
Processed dataset uploaded to MinIO.
Automated daily updates.


###Folder Structure
zreal-estate-data-engineering/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ kc_house_data.csv
â”‚   â””â”€â”€ kc_house_data_processed.csv
â”‚
â”œâ”€â”€ dagster_pipeline.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env

