# ğŸ¡ Real Estate Data Engineering Pipeline

This project is an end-to-end **real estate data pipeline** built with **Dagster**, featuring:

âœ… Web-scraping/CSV ingestion  
âœ… Change Data Capture (CDC) logic  
âœ… Uploading to **MinIO** (S3 compatible)  
âœ… Daily scheduled runs with **Dagster**  
âœ… Future-proof for machine learning, Superset dashboards, and more!

---

## ğŸš€ Tech Stack
- ğŸ—ï¸ **Dagster** â€“ Orchestration & scheduling  
- ğŸ§º **MinIO** â€“ Object storage (S3 compatible)  
- ğŸ“Š **Pandas** â€“ Data processing  
- â˜ï¸ **Boto3** â€“ Upload to MinIO  
- ğŸ³ **Docker** â€“ For MinIO local setup (optional)  
- ğŸ”„ **CDC** â€“ Detect changes and update data  

---

## ğŸ”§ How to Run

```bash
# 1ï¸âƒ£ Clone the repo
git clone https://github.com/ashishtammana/real-estate-data-engineering.git
cd real-estate-data-engineering

# 2ï¸âƒ£ Create and activate a virtual environment
python3 -m venv venv
source venv/bin/activate

# 3ï¸âƒ£ Install the dependencies
pip install -r requirements.txt

# 4ï¸âƒ£ Set up the environment variables
# Create a .env file in the root directory and add:
AWS_ACCESS_KEY_ID=your_minio_access_key
AWS_SECRET_ACCESS_KEY=your_minio_secret_key
MINIO_ENDPOINT=http://localhost:9000
MINIO_BUCKET=real-estate-data

# 5ï¸âƒ£ Start MinIO (optional if not already running)
docker-compose up -d

# 6ï¸âƒ£ Export Dagster home directory
export DAGSTER_HOME=~/dagster_home

# 7ï¸âƒ£ Start Dagster services in two terminals

# Terminal 1:
dagster-daemon run

# Terminal 2:
dagster-webserver -w workspace.yaml

# 8ï¸âƒ£ Open Dagster UI
# Go to:
http://localhost:3000

# 9ï¸âƒ£ Trigger the pipeline
# Run real_estate_pipeline manually from the Dagster UI or wait for the daily schedule.

---

##  ğŸ¯ âœ… Output
- Takes in raw real estate data (`kc_house_data.csv`).
- Cleans and processes the data, applying **CDC (Change Data Capture)** logic to detect and update only **new or changed records**.
- Generates a cleaned output file: `kc_house_data_processed.csv`.
- Uploads the processed dataset to **MinIO** under the **`real-estate-data`** bucket.
- Schedules automated **daily runs** through **Dagster** to keep the data fresh.
- Sets the foundation to plug in:
  - ğŸ¤– **Machine Learning models** (for future predictions).
  - ğŸ“Š **Superset dashboards** (for data visualization).

---

